{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "EXwE5RkhD5w-",
   "metadata": {
    "id": "EXwE5RkhD5w-"
   },
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "078472c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install rouge\n",
    "# !pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33105266",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4c7c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94bed4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(/"C:/Users/c_train_df_5k.csv\")\n",
    "test_df = pd.read_csv(/"C:/Users/c_test_df.csv\")\n",
    "val_df = pd.read_csv(/"C:/Users/c_dev_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d255eb15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=57458, step=1)\n",
      "Index(['Unnamed: 0', 'clean_article', 'clean_summary'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check DataFrame indices\n",
    "print(train_df.index)\n",
    "\n",
    "# Check DataFrame columns\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0a3053a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>clean_article</th>\n",
       "      <th>clean_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Liputan6. com, Indramayu : Kehebohan Alquran b...</td>\n",
       "      <td>Mohammad MM, Wahidin, dan Tanti Wydiasari meng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Liputan6. com, Jakarta : Baekuni atau Babe men...</td>\n",
       "      <td>Sebelum menjebak sejumlah korbannya, Babe tern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Liputan6. com, Jakarta : Bisnis bingkisan leba...</td>\n",
       "      <td>Bisnis bingkisan Lebaran di Ibu Kota kembali b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Liputan6. com, Makassar : Besse yang tengah ha...</td>\n",
       "      <td>Besse dan Bahir, anaknya yang berusia lima tah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Liputan6. com, Medan : Ngatini alias Maulida, ...</td>\n",
       "      <td>Ngatini tewas diduga keracunan chlorofil produ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      clean_article  \\\n",
       "0           0  Liputan6. com, Indramayu : Kehebohan Alquran b...   \n",
       "1           1  Liputan6. com, Jakarta : Baekuni atau Babe men...   \n",
       "2           2  Liputan6. com, Jakarta : Bisnis bingkisan leba...   \n",
       "3           3  Liputan6. com, Makassar : Besse yang tengah ha...   \n",
       "4           4  Liputan6. com, Medan : Ngatini alias Maulida, ...   \n",
       "\n",
       "                                       clean_summary  \n",
       "0  Mohammad MM, Wahidin, dan Tanti Wydiasari meng...  \n",
       "1  Sebelum menjebak sejumlah korbannya, Babe tern...  \n",
       "2  Bisnis bingkisan Lebaran di Ibu Kota kembali b...  \n",
       "3  Besse dan Bahir, anaknya yang berusia lima tah...  \n",
       "4  Ngatini tewas diduga keracunan chlorofil produ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>clean_article</th>\n",
       "      <th>clean_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Liputan6. com, Jakarta : Kasus pengeboman gere...</td>\n",
       "      <td>Sebuah bom meledak di Gereja Petra di Koja, Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Liputan6. com, Yogyakarta : Komisi A DPRD Daer...</td>\n",
       "      <td>Mahasiswa sekolah tinggi di Yogyakarta melibat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Liputan6. com, Jakarta : Menyusul sejumlah aks...</td>\n",
       "      <td>Dalam sepekan, dua bom menggemparkan Ibu Kota....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Liputan6. com, Jakarta : Rencana pemberian abo...</td>\n",
       "      <td>Pemberian abolisi kepada Soeharto lantaran kes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Liputan6. com, Jakarta : Ancaman mogok besar-b...</td>\n",
       "      <td>Pemerintah akan membayar rapel gaji guru palin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      clean_article  \\\n",
       "0           0  Liputan6. com, Jakarta : Kasus pengeboman gere...   \n",
       "1           1  Liputan6. com, Yogyakarta : Komisi A DPRD Daer...   \n",
       "2           2  Liputan6. com, Jakarta : Menyusul sejumlah aks...   \n",
       "3           3  Liputan6. com, Jakarta : Rencana pemberian abo...   \n",
       "4           4  Liputan6. com, Jakarta : Ancaman mogok besar-b...   \n",
       "\n",
       "                                       clean_summary  \n",
       "0  Sebuah bom meledak di Gereja Petra di Koja, Ja...  \n",
       "1  Mahasiswa sekolah tinggi di Yogyakarta melibat...  \n",
       "2  Dalam sepekan, dua bom menggemparkan Ibu Kota....  \n",
       "3  Pemberian abolisi kepada Soeharto lantaran kes...  \n",
       "4  Pemerintah akan membayar rapel gaji guru palin...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>clean_article</th>\n",
       "      <th>clean_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Liputan6. com, Surabaya : Radiogram Direktorat...</td>\n",
       "      <td>Gubernur Jatim Imam Utomo tak mau melantik Bup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Liputan6. com, Jakarta : Berbeda dengan aliran...</td>\n",
       "      <td>Pelukis RM Koestarto memamerkan hasil karyanya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Liputan6. com, Jambi : Ratusan orang dari Kesa...</td>\n",
       "      <td>Dua kelompok pengunjuk rasa di Jambi, menuntut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Liputan6. com, Jakarta : Badan Penyehatan Perb...</td>\n",
       "      <td>BPPN masih mengkaji bank rekap yang dianggap p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Liputan6. com, Jakarta : Ketua Komisi I DPR Ya...</td>\n",
       "      <td>Kendati Dewan Papua membatalkan deklarasi keme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      clean_article  \\\n",
       "0           0  Liputan6. com, Surabaya : Radiogram Direktorat...   \n",
       "1           1  Liputan6. com, Jakarta : Berbeda dengan aliran...   \n",
       "2           2  Liputan6. com, Jambi : Ratusan orang dari Kesa...   \n",
       "3           3  Liputan6. com, Jakarta : Badan Penyehatan Perb...   \n",
       "4           4  Liputan6. com, Jakarta : Ketua Komisi I DPR Ya...   \n",
       "\n",
       "                                       clean_summary  \n",
       "0  Gubernur Jatim Imam Utomo tak mau melantik Bup...  \n",
       "1  Pelukis RM Koestarto memamerkan hasil karyanya...  \n",
       "2  Dua kelompok pengunjuk rasa di Jambi, menuntut...  \n",
       "3  BPPN masih mengkaji bank rekap yang dianggap p...  \n",
       "4  Kendati Dewan Papua membatalkan deklarasi keme...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())\n",
    "\n",
    "display(test_df.head())\n",
    "\n",
    "display(val_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d00285dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57458 entries, 0 to 57457\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Unnamed: 0     57458 non-null  int64 \n",
      " 1   clean_article  57458 non-null  object\n",
      " 2   clean_summary  57458 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10972 entries, 0 to 10971\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Unnamed: 0     10972 non-null  int64 \n",
      " 1   clean_article  10972 non-null  object\n",
      " 2   clean_summary  10972 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 257.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10972 entries, 0 to 10971\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Unnamed: 0     10972 non-null  int64 \n",
      " 1   clean_article  10972 non-null  object\n",
      " 2   clean_summary  10972 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 257.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.info())\n",
    "print('*'*50)\n",
    "display(test_df.info())\n",
    "print('*'*50)\n",
    "display(val_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9df22bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import Dataset\n",
    "from transformers import BertModel, BertTokenizer, BertConfig, BertForSequenceClassification\n",
    "from transformers import EncoderDecoderConfig, EncoderDecoderModel\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "from transformers import pipeline\n",
    "from rouge import Rouge\n",
    "from datasets import load_metric\n",
    "from transformers import PretrainedConfig\n",
    "from transformers import BertConfig, EncoderDecoderConfig\n",
    "from transformers import BertPreTrainedModel, BertModel\n",
    "from transformers.models.bart.modeling_bart import BartForConditionalGeneration\n",
    "import transformers\n",
    "from transformers.generation_utils import GenerationMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78013dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_dict(train_df)\n",
    "test_data = Dataset.from_dict(test_df)\n",
    "val_data = Dataset.from_dict(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cbd3ad4-4f22-4150-a250-553d905592b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T15:41:08.539790Z",
     "iopub.status.busy": "2023-12-01T15:41:08.539420Z",
     "iopub.status.idle": "2023-12-01T15:41:12.141617Z",
     "shell.execute_reply": "2023-12-01T15:41:12.140844Z",
     "shell.execute_reply.started": "2023-12-01T15:41:08.539764Z"
    },
    "id": "0cbd3ad4-4f22-4150-a250-553d905592b2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load TinyBert tokenizer with authentication token\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "tokenizer.bos_token = tokenizer.cls_token\n",
    "tokenizer.eos_token = tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "lJ71TtivJ_g1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJ71TtivJ_g1",
    "outputId": "9ca96575-be62-4bf2-9433-b148d0f92d97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[CLS]', '[SEP]', 101, 102)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token, tokenizer.eos_token, tokenizer.get_vocab()[tokenizer.bos_token], tokenizer.get_vocab()[tokenizer.eos_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7bed314-8d26-4fee-bb70-a30537c5bb89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T15:41:12.143652Z",
     "iopub.status.busy": "2023-12-01T15:41:12.143099Z",
     "iopub.status.idle": "2023-12-01T15:41:12.148365Z",
     "shell.execute_reply": "2023-12-01T15:41:12.147590Z",
     "shell.execute_reply.started": "2023-12-01T15:41:12.143624Z"
    },
    "id": "d7bed314-8d26-4fee-bb70-a30537c5bb89",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = tokenizer.bos_token + \" \"\n",
    "posfix = \" \" + tokenizer.eos_token\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + str(doc) + posfix for doc in examples[\"clean_article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
    "    labels = tokenizer(text=examples[\"clean_summary\"], max_length=128, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38437260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/57458 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_Indo_news_train = train_data.map(preprocess_function, batched=True)\n",
    "tokenized_Indo_news_dev = val_data.map(preprocess_function, batched=True)\n",
    "tokenized_Indo_news_test = test_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb054abd-6d3e-4c41-84bb-49d694256f19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T15:41:18.392008Z",
     "iopub.status.busy": "2023-12-01T15:41:18.391647Z",
     "iopub.status.idle": "2023-12-01T15:41:18.773876Z",
     "shell.execute_reply": "2023-12-01T15:41:18.773160Z",
     "shell.execute_reply.started": "2023-12-01T15:41:18.391981Z"
    },
    "id": "fb054abd-6d3e-4c41-84bb-49d694256f19",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertConfig, EncoderDecoderConfig, EncoderDecoderModel\n",
    "\n",
    "config_encoder = BertConfig(\n",
    "    vocab_size = len(tokenizer.get_vocab()), # sesuaikan dengan vocab tokenizer\n",
    "    hidden_size = 36,\n",
    "    num_hidden_layers = 6,\n",
    "    num_attention_heads = 6,\n",
    "    intermediate_size = 768,\n",
    ")\n",
    "config_decoder = BertConfig(\n",
    "    vocab_size = len(tokenizer.get_vocab()), # sesuaikan dengan vocab tokenizer\n",
    "    hidden_size = 36,\n",
    "    num_hidden_layers = 6,\n",
    "    num_attention_heads = 6,\n",
    "    intermediate_size = 768,\n",
    ")\n",
    "\n",
    "config = EncoderDecoderConfig.from_encoder_decoder_configs(config_encoder, config_decoder)\n",
    "model = EncoderDecoderModel(config=config)\n",
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69136685-5baa-450a-b54b-e755dd65471f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T15:41:18.775234Z",
     "iopub.status.busy": "2023-12-01T15:41:18.774890Z",
     "iopub.status.idle": "2023-12-01T15:41:19.118601Z",
     "shell.execute_reply": "2023-12-01T15:41:19.117723Z",
     "shell.execute_reply.started": "2023-12-01T15:41:18.775210Z"
    },
    "id": "69136685-5baa-450a-b54b-e755dd65471f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3fdc298-7416-413e-9602-d412f4581344",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T15:41:19.120221Z",
     "iopub.status.busy": "2023-12-01T15:41:19.119819Z",
     "iopub.status.idle": "2023-12-01T15:41:19.124302Z",
     "shell.execute_reply": "2023-12-01T15:41:19.123587Z",
     "shell.execute_reply.started": "2023-12-01T15:41:19.120192Z"
    },
    "id": "a3fdc298-7416-413e-9602-d412f4581344",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model='t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "036f4ff8-c32f-4a45-acf0-8959204490b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T15:44:39.237198Z",
     "iopub.status.busy": "2023-12-01T15:44:39.236716Z",
     "iopub.status.idle": "2023-12-01T15:44:39.243233Z",
     "shell.execute_reply": "2023-12-01T15:44:39.242460Z",
     "shell.execute_reply.started": "2023-12-01T15:44:39.237158Z"
    },
    "id": "036f4ff8-c32f-4a45-acf0-8959204490b3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "# Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    per_device_train_batch_size=4,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    fp16=False  # Set fp16 to False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2d627bf-d444-4a0f-8682-fb8d0fd6f1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T15:44:40.236266Z",
     "iopub.status.busy": "2023-12-01T15:44:40.235870Z",
     "iopub.status.idle": "2023-12-01T15:44:40.547081Z",
     "shell.execute_reply": "2023-12-01T15:44:40.545855Z",
     "shell.execute_reply.started": "2023-12-01T15:44:40.236241Z"
    },
    "id": "e2d627bf-d444-4a0f-8682-fb8d0fd6f1ec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and configure the trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_Indo_news_train,\n",
    "    eval_dataset=tokenized_Indo_news_dev,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb6b2c13-e1eb-41b3-93b1-69ba25bf4513",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "execution": {
     "iopub.execute_input": "2023-12-01T15:42:06.236479Z",
     "iopub.status.busy": "2023-12-01T15:42:06.236090Z",
     "iopub.status.idle": "2023-12-01T15:42:07.588424Z",
     "shell.execute_reply": "2023-12-01T15:42:07.586921Z",
     "shell.execute_reply.started": "2023-12-01T15:42:06.236454Z"
    },
    "id": "cb6b2c13-e1eb-41b3-93b1-69ba25bf4513",
    "outputId": "b3d8ac2d-0504-4a57-807b-de3de75e4a1c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14365' max='14365' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14365/14365 12:04:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>9.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>7.439400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>6.885900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>6.619800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>6.510600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>6.454400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>6.413100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>6.373500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>6.325800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>6.268300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>6.201100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>6.140600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>6.089600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>6.039900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>5.982700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>5.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>5.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>5.863900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>5.852300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>5.798200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>5.796600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>5.771500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>5.752900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>5.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>5.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>5.727400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>5.716200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "C:\\Users\\ejhas\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12h 4min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14365, training_loss=6.317254037455403, metrics={'train_runtime': 43462.8814, 'train_samples_per_second': 1.322, 'train_steps_per_second': 0.331, 'total_flos': 139139136819072.0, 'train_loss': 6.317254037455403, 'epoch': 1.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eacdf76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_summary(document):\n",
    "    # Tokenize the document with token_type_ids\n",
    "    inputs = tokenizer(document, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"longest\", return_token_type_ids=True)\n",
    "    inputs = {k: v for k, v in inputs.items()}\n",
    "\n",
    "    # Remove 'token_type_ids' from inputs\n",
    "    inputs.pop('token_type_ids', None)\n",
    "\n",
    "    # Generate the summary\n",
    "    summary_ids = model.generate(**inputs, max_length=128)\n",
    "    predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return predicted_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "037456b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The following `model_kwargs` are not used by the model: ['token_type_ids'] (note: typos in the generate arguments will also show up in this list)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17664\\1946161062.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Example usage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredicted_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17664\\3757853043.py\u001b[0m in \u001b[0;36mpredict_summary\u001b[1;34m(document)\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mtokenized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdocument\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'longest'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mtokenized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m   \u001b[0mtokenized_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m   \u001b[0mtokenized_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenized_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mpredicted_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\generation\\utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[0;32m   1269\u001b[0m         \u001b[0mmodel_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# All unused kwargs must be model kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m         \u001b[0mgeneration_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1271\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_model_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m         \u001b[1;31m# 2. Set generation parameters if not already defined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\generation\\utils.py\u001b[0m in \u001b[0;36m_validate_model_kwargs\u001b[1;34m(self, model_kwargs)\u001b[0m\n\u001b[0;32m   1143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0munused_model_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1145\u001b[1;33m                 \u001b[1;34mf\"The following `model_kwargs` are not used by the model: {unused_model_args} (note: typos in the\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m                 \u001b[1;34m\" generate arguments will also show up in this list)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: The following `model_kwargs` are not used by the model: ['token_type_ids'] (note: typos in the generate arguments will also show up in this list)"
     ]
    }
   ],
   "source": [
    "article = test_data['clean_article'][0]\n",
    "summary = test_data['clean_summary'][0]\n",
    "\n",
    "# Example usage\n",
    "predicted_summary = predict_summary(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BsAY5fq9Mfx1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "BsAY5fq9Mfx1",
    "outputId": "e731c94f-0b5b-46b7-cf8b-a826ad788914"
   },
   "outputs": [],
   "source": [
    "predicted_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2odnomeYMubf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "2odnomeYMubf",
    "outputId": "b9428d04-75e2-4244-f46c-339c92b9a532"
   },
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "EaizVtKyM04q",
   "metadata": {
    "id": "EaizVtKyM04q"
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "def get_rouge_scores(actual_summary, predicted_summary):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(predicted_summary, actual_summary)\n",
    "    return [scores[0]['rouge-1']['f'], scores[0]['rouge-2']['f'], scores[0]['rouge-l']['f']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "relmUSV8M3Fv",
   "metadata": {
    "id": "relmUSV8M3Fv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10972/10972 [24:13:52<00:00,  7.95s/it]\n"
     ]
    }
   ],
   "source": [
    "# rouge score of validation data\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "rouge1_scores = []\n",
    "rouge2_scores = []\n",
    "rougel_scores = []\n",
    "\n",
    "pred_summary_list = []\n",
    "\n",
    "for i in tqdm(range(len(tokenized_Indo_news_test['clean_summary']))):\n",
    "\n",
    "  doc = tokenized_Indo_news_test['clean_article'][i]\n",
    "  pred_summary = predict_summary(doc)\n",
    "  human_summary = tokenized_Indo_news_test['clean_summary'][i]\n",
    "\n",
    "  score = get_rouge_scores(human_summary, pred_summary)\n",
    "\n",
    "  rouge1_scores.append(score[0])\n",
    "  rouge2_scores.append(score[1])\n",
    "  rougel_scores.append(score[2])\n",
    "\n",
    "  pred_summary_list.append(pred_summary)\n",
    "\n",
    "eval = pd.DataFrame({\n",
    "    \"pred_summary\" : pred_summary_list,\n",
    "    \"rouge1\" : rouge1_scores,\n",
    "    \"rouge2\" : rouge2_scores,\n",
    "    \"rougel\" : rougel_scores,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36r56j50NK1C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36r56j50NK1C",
    "outputId": "6df232c8-43ae-4b49-cc55-234f8c7a6d73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024552014768989397"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average rouge 1\n",
    "eval['rouge1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8aHM_9WNgrr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8aHM_9WNgrr",
    "outputId": "4d18c6c0-a70e-4181-c85d-02f979b75dc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average rouge 2\n",
    "eval['rouge2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "JgNtP8sTNdct",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgNtP8sTNdct",
    "outputId": "90a5e216-c4f2-468f-b77d-300ce6b5eab8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024552014768989397"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average rouge l\n",
    "eval['rougel'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "sqW3xp0GNQa0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "sqW3xp0GNQa0",
    "outputId": "3f2824d0-ea9b-4616-e4d4-fa6ecbc3825d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_summary</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kembaa.tun dimbaa.n di sebui.n.n.i.n.i.a.n di ...</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kembaga.i.i.i.a.i.a.i.a.a.i.n.n.a.a.a.a.i.a.a....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kembak di setun.n.n.i.i.n.n.i.i.n.n.n.n.i.i.a....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>di sebun.n.i.i.n.i.n.n.a.a.i.i.i.i.n.n.n.n.n.i...</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sebuk, sebun.n.n.a.i.n.i.n.n.a.a.i.i.n.n.n.n.a...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10967</th>\n",
       "      <td>kembaga di setun di sebun di sebun.n.i.i.ah.n....</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10968</th>\n",
       "      <td>sebun di kembaga di sebun.n di setun.a.n.n.a.n...</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10969</th>\n",
       "      <td>kembak di kembaa.n di kembaga.n.i.n.i.n.n.a.n....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10970</th>\n",
       "      <td>sebun.i.n di kembaga.n.n.a.i.n.i.n.i.i.n.n.n.a...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10971</th>\n",
       "      <td>kembak di kembak di sebun di kembaa.n.n.n.i.i....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10972 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pred_summary    rouge1  rouge2  \\\n",
       "0      kembaa.tun dimbaa.n di sebui.n.n.i.n.i.a.n di ...  0.054054     0.0   \n",
       "1      kembaga.i.i.i.a.i.a.i.a.a.i.n.n.a.a.a.a.i.a.a....  0.000000     0.0   \n",
       "2      kembak di setun.n.n.i.i.n.n.i.i.n.n.n.n.i.i.a....  0.000000     0.0   \n",
       "3      di sebun.n.i.i.n.i.n.n.a.a.i.i.i.i.n.n.n.n.n.i...  0.068966     0.0   \n",
       "4      sebuk, sebun.n.n.a.i.n.i.n.n.a.a.i.i.n.n.n.n.a...  0.000000     0.0   \n",
       "...                                                  ...       ...     ...   \n",
       "10967  kembaga di setun di sebun di sebun.n.i.i.ah.n....  0.062500     0.0   \n",
       "10968  sebun di kembaga di sebun.n di setun.a.n.n.a.n...  0.060606     0.0   \n",
       "10969  kembak di kembaa.n di kembaga.n.i.n.i.n.n.a.n....  0.000000     0.0   \n",
       "10970  sebun.i.n di kembaga.n.n.a.i.n.i.n.i.i.n.n.n.a...  0.000000     0.0   \n",
       "10971  kembak di kembak di sebun di kembaa.n.n.n.i.i....  0.000000     0.0   \n",
       "\n",
       "         rougel  \n",
       "0      0.054054  \n",
       "1      0.000000  \n",
       "2      0.000000  \n",
       "3      0.068966  \n",
       "4      0.000000  \n",
       "...         ...  \n",
       "10967  0.062500  \n",
       "10968  0.060606  \n",
       "10969  0.000000  \n",
       "10970  0.000000  \n",
       "10971  0.000000  \n",
       "\n",
       "[10972 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SB5Sz-mdO1iX",
   "metadata": {
    "id": "SB5Sz-mdO1iX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "020ca37bcd944fffb218d1773aba94c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a36a42cf45144278f2838bb843f060c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_020ca37bcd944fffb218d1773aba94c9",
      "max": 400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf618d0e1ab548fdb02a5427ee78e424",
      "value": 400
     }
    },
    "1fe0a55e9d134d63ad14afa9a3ed535e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a6249f9a0a84ea091f14a1973837175": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58375c93d7eb4f588414a3189b16fc21",
      "placeholder": "​",
      "style": "IPY_MODEL_d2458a59ad3d42718ba41357d146171e",
      "value": " 400/400 [00:11&lt;00:00, 34.36 examples/s]"
     }
    },
    "2c34cbd59219429c993aeadf1e50cd0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36bd9f6d36ac412eba26d142f9604114": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f89d494e42a43c3860628d2898ec0f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58375c93d7eb4f588414a3189b16fc21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b3df6b1a2054ca79744a55c39312e32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "923674b5f7bc489d9b9317ab345b3785": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9476729f7c074d2ea5e79a150eb00a53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d94706b90f3c42b98986e2ac28736e0d",
      "placeholder": "​",
      "style": "IPY_MODEL_1fe0a55e9d134d63ad14afa9a3ed535e",
      "value": "Map: 100%"
     }
    },
    "c176e78f6e4c4f56b09503a5e0811402": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3453e1906c0438da0b0760bbbc92612": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_923674b5f7bc489d9b9317ab345b3785",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b3df6b1a2054ca79744a55c39312e32",
      "value": 100
     }
    },
    "c6b9d1ce04a04805a7409d35fef4b88f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cabf4880b3114d13913b964994b4f7b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e5b3721bdff949b3bd6fb116baf35d86",
       "IPY_MODEL_1a36a42cf45144278f2838bb843f060c",
       "IPY_MODEL_2a6249f9a0a84ea091f14a1973837175"
      ],
      "layout": "IPY_MODEL_4f89d494e42a43c3860628d2898ec0f4"
     }
    },
    "cd731ed7a3b1498fa513bb987f408bf7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf618d0e1ab548fdb02a5427ee78e424": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d2458a59ad3d42718ba41357d146171e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d94706b90f3c42b98986e2ac28736e0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5b3721bdff949b3bd6fb116baf35d86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c176e78f6e4c4f56b09503a5e0811402",
      "placeholder": "​",
      "style": "IPY_MODEL_36bd9f6d36ac412eba26d142f9604114",
      "value": "Map: 100%"
     }
    },
    "ebfde0295f3544b5b0f5b91a3ed5de76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd731ed7a3b1498fa513bb987f408bf7",
      "placeholder": "​",
      "style": "IPY_MODEL_2c34cbd59219429c993aeadf1e50cd0c",
      "value": " 100/100 [00:02&lt;00:00, 39.94 examples/s]"
     }
    },
    "f225482231af4e278f1990e1b22b9ada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9476729f7c074d2ea5e79a150eb00a53",
       "IPY_MODEL_c3453e1906c0438da0b0760bbbc92612",
       "IPY_MODEL_ebfde0295f3544b5b0f5b91a3ed5de76"
      ],
      "layout": "IPY_MODEL_c6b9d1ce04a04805a7409d35fef4b88f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
